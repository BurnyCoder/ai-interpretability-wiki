<onlyinclude>In machine learning, '''[[Grokking|grokking]]''', or '''delayed generalization''', is a phenomenon observed in some settings where a model abruptly transitions from overfitting (performing well only on training data) to generalizing (performing well on both training and test data), after many training iterations with little or no improvement on the held-out data.<ref>[https://arxiv.org/abs/2201.02177 Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets — arXiv] (paper)</ref><ref>[https://en.wikipedia.org/wiki/Grokking_(machine_learning) Grokking (machine learning) — Wikipedia]</ref> This contrasts with what is typically observed in machine learning, where generalization occurs gradually alongside improved performance on training data.</onlyinclude>

== References ==

<references />

[[Category:Phenomena]]
