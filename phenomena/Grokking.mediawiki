<onlyinclude>'''[[Grokking]]''', or '''delayed generalization''', is a phenomenon observed in some settings where a model abruptly transitions from overfitting (performing well only on training data) to generalizing (performing well on both training and test data), after many training iterations with little or no improvement on the held-out data.<ref>[https://en.wikipedia.org/wiki/Grokking_(machine_learning) Grokking (machine learning) â€” Wikipedia]</ref><ref>[[Progress measures for grokking via mechanistic interpretability]]</ref> This contrasts with what is typically observed in machine learning, where generalization occurs gradually alongside improved performance on training data.</onlyinclude>

== References ==

<references />

[[Category:Phenomena]]
