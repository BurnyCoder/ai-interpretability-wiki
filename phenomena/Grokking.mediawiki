:''Not to be confused with [[w:Grok (chatbot)|Grok (chatbot)]].''

<onlyinclude>
In [[w:Machine learning|machine learning]], '''[[Grokking]]''', or '''delayed generalization''', is a phenomenon observed in some settings where a model abruptly transitions from [[w:Overfitting|overfitting]] (performing well only on [[w:Training data|training data]]) to [[w:Generalization (learning)|generalizing]] (performing well on both training and test data), after many training iterations with little or no improvement on the held-out data.<ref name="quanta">Ananthaswamy, Anil (2024-04-12). [https://www.quantamagazine.org/how-do-machines-grok-data-20240412/ "How Do Machines 'Grok' Data?"]. ''Quanta Magazine''.</ref><ref name="power2022">Power, Alethea; Burda, Yuri; Edwards, Harri; et al. (2022). [https://arxiv.org/abs/2201.02177 "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets"]. arXiv:[https://arxiv.org/abs/2201.02177 2201.02177].</ref> This contrasts with what is typically observed in machine learning, where generalization occurs gradually alongside improved performance on training data.<ref>Pearce, Adam; Ghandeharioun, Asma; Hussein, Nada; et al. [https://pair.withgoogle.com/explorables/grokking/ "Do Machine Learning Models Memorize or Generalize?"]. ''pair.withgoogle.com''.</ref><ref>Minegishi, Gouki; Iwasawa, Yusuke; Matsuo, Yutaka (2024). [https://arxiv.org/abs/2310.19470 "Bridging Lottery ticket and Grokking: Is Weight Norm Sufficient to Explain Delayed Generalization?"]. arXiv:[https://arxiv.org/abs/2310.19470 2310.19470].</ref>
</onlyinclude>

== Etymology ==

''Grokking'' was introduced in January 2022 by [[w:OpenAI|OpenAI]] researchers who were studying generalization on small datasets. It is derived from the word ''[[w:Grok|grok]]'' coined by [[w:Robert A. Heinlein|Robert Heinlein]] in his novel ''[[w:Stranger in a Strange Land|Stranger in a Strange Land]]''.<ref name="quanta" /> In ML research, "grokking" is ''not'' used as a synonym for "generalization"; rather, it names a sometimes-observed delayed-generalization training phenomenon in which training and held-out performance do not improve in tandem, and in which held-out performance rises abruptly later. Authors also analyze the "grokking time", the [[w:Glossary of artificial intelligence#epoch|epoch]] or step at which this transition occurs in those scenarios.<ref name="power2022" />

== Interpretations ==

Grokking can be understood as a [[w:Phase transition|phase transition]] during the training process.<ref>Liu, Ziming; Kitouni, Ouail; Nolte, Niklas; et al. (2022). [https://papers.nips.cc/paper_files/paper/2022/hash/dfc310e81992d2e4cedc09ac47eff13e-Abstract-Conference.html "Towards Understanding Grokking: An Effective Theory of Representation Learning"]. ''Advances in Neural Information Processing Systems 35 (NeurIPS 2022)''. arXiv:[https://arxiv.org/abs/2205.10343 2205.10343].</ref> In particular, recent work has shown that grokking may be due to a [[w:Kolmogorov complexity|complexity]] phase transition in the model during training.<ref>DeMoss, Branton; Sapora, Silvia; Foerster, Jakob; et al. (2025). [https://www.sciencedirect.com/science/article/pii/S0167278925003367 "The complexity dynamics of grokking"]. ''Physica D: Nonlinear Phenomena''. '''482''': 134859. doi:[https://doi.org/10.1016/j.physd.2025.134859 10.1016/j.physd.2025.134859].</ref> While grokking has been thought of as largely a phenomenon of relatively shallow models, grokking has been observed in deep neural networks and non-neural models and is the subject of active research.<ref>Fan, Simin; Pascanu, Razvan; Jaggi, Martin (2024). [https://arxiv.org/abs/2405.19454 "Deep Grokking: Would Deep Neural Networks Generalize Better?"]. arXiv:[https://arxiv.org/abs/2405.19454 2405.19454].</ref><ref>Miller, Jack; O'Neill, Charles; Bui, Thang (2024). [https://arxiv.org/abs/2310.17247 "Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity"]. arXiv:[https://arxiv.org/abs/2310.17247 2310.17247].</ref><ref name="omnigrok">Liu, Ziming; Michaud, Eric J.; Tegmark, Max (2023). [https://openreview.net/pdf?id=zDiHoIWa0q1 "Omnigrok: Grokking Beyond Algorithmic Data"]. ''International Conference on Learning Representations (ICLR 2023)''. arXiv:[https://arxiv.org/abs/2210.01117 2210.01117].</ref><ref>Samothrakis, Spyridon; Matran-Fernandez, Ana; Abdullahi, Umar I.; et al. (2022). [https://repository.essex.ac.uk/34514/ "Grokking-like effects in counterfactual inference"]. ''International Joint Conference on Neural Networks (IJCNN 2022)''. pp. 1â€“8. doi:[https://doi.org/10.1109/IJCNN55064.2022.9891910 10.1109/IJCNN55064.2022.9891910].</ref>

One potential explanation is that the [[w:Weight decay|weight decay]] (a component of the loss function that penalizes higher values of the neural network parameters, also called [[w:Regularization (mathematics)|regularization]]) slightly favors the general solution that involves lower weight values, but that is also harder to find. According to Neel Nanda, the process of learning the general solution may be gradual, even though the transition to the general solution occurs more suddenly later.<ref name="quanta" />

Recent theories<ref>Kumar, Tanishq; Bordelon, Blake; Gershman, Samuel J.; et al. (2023). [https://arxiv.org/abs/2310.06110 "Grokking as the Transition from Lazy to Rich Training Dynamics"]. arXiv:[https://arxiv.org/abs/2310.06110 2310.06110].</ref><ref>Lyu, Kaifeng; Jin, Jikai; Li, Zhiyuan; et al. (2023). [https://arxiv.org/abs/2311.18817 "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking"]. arXiv:[https://arxiv.org/abs/2311.18817 2311.18817].</ref> have hypothesized that grokking occurs when neural networks transition from a "lazy training"<ref>Chizat, Lenaic; Oyallon, Edouard; Bach, Francis (2018). [https://arxiv.org/abs/1812.07956 "On Lazy Training in Differentiable Programming"]. arXiv:[https://arxiv.org/abs/1812.07956 1812.07956].</ref> regime where the weights do not deviate far from initialization, to a "rich" regime where weights abruptly begin to move in task-relevant directions. Follow-up empirical and theoretical work<ref>Mohamadi, Mohamad Amin; Li, Zhiyuan; Wu, Lei; et al. (2024). [https://arxiv.org/abs/2407.12332 "Why do You Grok? A Theoretical Analysis of Grokking Modular Addition"]. arXiv:[https://arxiv.org/abs/2407.12332 2407.12332].</ref> has accumulated evidence in support of this perspective, and it offers a unifying view of earlier work as the transition from lazy to rich training dynamics is known to arise from properties of adaptive optimizers,<ref>Thilak, Vimal; Littwin, Etai; Zhai, Shuangfei; et al. (2022). [https://arxiv.org/abs/2206.04817 "The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon"]. arXiv:[https://arxiv.org/abs/2206.04817 2206.04817].</ref> weight decay,<ref>Varma, Vikrant; Shah, Rohin; Kenton, Zachary; et al. (2023). [https://arxiv.org/abs/2309.02390 "Explaining grokking through circuit efficiency"]. arXiv:[https://arxiv.org/abs/2309.02390 2309.02390].</ref> initial parameter weight norm,<ref name="omnigrok" /> and more. This perspective is complementary to a unifying "pattern learning speeds" framework that links grokking and [[w:Double descent|double descent]]; within this view, delayed generalization can arise across training time ("epoch-wise") or across model size ("model-wise"), and the authors report "model-wise grokking".<ref>Davies, Xander; Langosco, Lauro; Krueger, David (2023). [https://arxiv.org/abs/2303.06173 "Unifying Grokking and Double Descent"]. arXiv:[https://arxiv.org/abs/2303.06173 2303.06173].</ref>

== References ==

<references />

[[Category:Phenomena]]
