# AI Interpretability Wiki

A local mirror of the [AI Interpretability Wiki](https://aiinterpretability.miraheze.org/), written in MediaWiki and hosted on Miraheze.

## About

**Interpretability** is the ability for the decision processes and inner workings of AI and machine learning systems to be understood by humans or other outside observers.

**Mechanistic interpretability** (often abbreviated as **mech interp**, **mechinterp**, or **MI**) is a subfield of research within AI interpretability and explainable artificial intelligence that aims to understand the internal workings of neural networks by analyzing the mechanisms present in their computations. The approach seeks to analyze neural networks in a manner similar to how binary computer programs can be reverse-engineered to understand their functions.

## Contents

| Category | Description |
|----------|-------------|
| Highlighted work | Notable and influential work in AI interpretability |
| Concepts | Core ideas and terminology |
| Methods | Techniques and approaches used to interpret models |
| Interpretability architectures | Architectures and frameworks used for AI interpretability |
| Applications | Practical uses and deployments |
| Phenomena | Behaviors and properties analyzed |
| AI architectures | Architectures of models studied |
| Theory | Theoretical foundations, mathematical and formal frameworks in AI and AI interpretability |
| Surveys | Survey papers and literature reviews |
| Github codebases | Code repositories |
| People and groups | Researchers, labs, and organizations |
| Communities | Communities on Discord, Slack, etc. |
| Feeds | Blogs, newsletters, and content feeds |
| Youtube channels | Video content and educational channels |
| Resources for learning | Tutorials, courses, and learning materials |
| Events | Conferences, workshops, and meetups |
