<onlyinclude>
'''[[Sparse autoencoder]]''' ('''SAE''') is "a weak dictionary learning algorithm to generate learned [[Feature|features]] from a trained model that offer a more monosemantic unit of analysis than the model's neurons themselves."<ref name="towards-monosemanticity">Bricken, Trenton; Templeton, Adly; Batson, Joshua; et al. (2023). [https://transformer-circuits.pub/2023/monosemantic-features/index.html "Towards Monosemanticity: Decomposing Language Models With Dictionary Learning"]. ''Transformer Circuits Thread''.</ref>
</onlyinclude>

Sparse autoencoders address polysemanticity, where "many neurons are polysemantic: they respond to mixtures of seemingly unrelated inputs," caused by superposition, "a hypothesized phenomenon where a neural network represents more independent 'features' of the data than it has neurons by assigning each feature its own linear combination of neurons," by extracting "relatively monosemantic features" that are "effectively invisible in the neuron basis."<ref name="towards-monosemanticity" />

== References ==

<references />

[[Category:Architectures for interpretability]]
